{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "This is an adaptation of the experiment on Single Digit Addition, on a more complicated setup with multiple digits.\n",
    "\n",
    "Consider the classifier $\\mathtt{addition([X_1,X_2],[Y_1,Y_2],N)}$. $\\mathtt{[X_1,X_2]}$ and $\\mathtt{[Y_1,Y_2]}$ are lists of images of digits, representing two multi-digit numbers; $\\mathtt{N}$ is a natural number corresponding to the sum of the two multi-digit numbers. The classifier must return a confidence in the validity of the addition.\n",
    "\n",
    "The steps are similar to that of the Single Digit Addition example (read the first notebook for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import logictensornetworks as ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of images for the digits X1, X2, Y1 and Y2, and their label Z s.t. 10\\*X1+X2+10\\*X2+Y2=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is 126\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=4,\n",
    "        op=lambda args: 10*args[0]+args[1]+10*args[2]+args[3])\n",
    "\n",
    "# Visualize one example\n",
    "x1, x2, y1, y2, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(221)\n",
    "plt.imshow(x1[0][:,:,0])\n",
    "plt.subplot(222)\n",
    "plt.imshow(x2[0][:,:,0])\n",
    "plt.subplot(223)\n",
    "plt.imshow(y1[0][:,:,0])\n",
    "plt.subplot(224)\n",
    "plt.imshow(y2[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTN Model and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predicates\n",
    "logits_model = baselines.SingleDigit()\n",
    "Digit = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model))\n",
    "### Variables\n",
    "d1 = ltn.variable(\"digits1\", range(10))\n",
    "d2 = ltn.variable(\"digits2\", range(10))\n",
    "d3 = ltn.variable(\"digits3\", range(10))\n",
    "d4 = ltn.variable(\"digits4\", range(10))\n",
    "### Operators\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0002105236>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def axioms(images_x1,images_x2,images_y1,images_y2,labels_z,p_schedule):\n",
    "    images_x1 = ltn.variable(\"x1\", images_x1)\n",
    "    images_x2 = ltn.variable(\"x2\", images_x2)\n",
    "    images_y1 = ltn.variable(\"y1\", images_y1)\n",
    "    images_y2 = ltn.variable(\"y2\", images_y2)\n",
    "    labels_z = ltn.variable(\"z\", labels_z)\n",
    "    return Forall(\n",
    "            ltn.diag(images_x1,images_x2,images_y1,images_y2,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2,d3,d4),\n",
    "                And(\n",
    "                    And(Digit([images_x1,d1]),Digit([images_x2,d2])),\n",
    "                    And(Digit([images_y1,d3]),Digit([images_y2,d4]))\n",
    "                ),\n",
    "                mask_vars=[d1,d2,d3,d4,labels_z],\n",
    "                mask_fn=lambda vars: tf.equal(10*vars[0]+vars[1]+10*vars[2]+vars[3],vars[4]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "\n",
    "x1, x2, y1, y2, z = next(ds_train.as_numpy_iterator())\n",
    "axioms(x1, x2, y1, y2, z, tf.constant(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x1 = tf.argmax(logits_model(images_x1),axis=-1)\n",
    "    predictions_x2 = tf.argmax(logits_model(images_x2),axis=-1)\n",
    "    predictions_y1 = tf.argmax(logits_model(images_y1),axis=-1)\n",
    "    predictions_y2 = tf.argmax(logits_model(images_y2),axis=-1)\n",
    "    predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x1 = tf.argmax(logits_model(images_x1),axis=-1)\n",
    "    predictions_x2 = tf.argmax(logits_model(images_x2),axis=-1)\n",
    "    predictions_y1 = tf.argmax(logits_model(images_y1),axis=-1)\n",
    "    predictions_y2 = tf.argmax(logits_model(images_y2),axis=-1)\n",
    "    predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer single_digit is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0, train_loss: 0.9974, train_accuracy: 0.1499, test_loss: 0.9913, test_accuracy: 0.4266\n",
      "Epoch 1, train_loss: 0.9870, train_accuracy: 0.7031, test_loss: 0.9865, test_accuracy: 0.6915\n",
      "Epoch 2, train_loss: 0.9845, train_accuracy: 0.8125, test_loss: 0.9860, test_accuracy: 0.6895\n",
      "Epoch 3, train_loss: 0.9836, train_accuracy: 0.8471, test_loss: 0.9848, test_accuracy: 0.7778\n",
      "Epoch 4, train_loss: 0.8939, train_accuracy: 0.8511, test_loss: 0.8978, test_accuracy: 0.7907\n",
      "Epoch 5, train_loss: 0.8861, train_accuracy: 0.8906, test_loss: 0.8909, test_accuracy: 0.8363\n",
      "Epoch 6, train_loss: 0.8831, train_accuracy: 0.9079, test_loss: 0.8925, test_accuracy: 0.8284\n",
      "Epoch 7, train_loss: 0.8806, train_accuracy: 0.9219, test_loss: 0.8896, test_accuracy: 0.8542\n",
      "Epoch 8, train_loss: 0.6913, train_accuracy: 0.9062, test_loss: 0.7214, test_accuracy: 0.8065\n",
      "Epoch 9, train_loss: 0.6857, train_accuracy: 0.9169, test_loss: 0.7179, test_accuracy: 0.8224\n",
      "Epoch 10, train_loss: 0.6786, train_accuracy: 0.9279, test_loss: 0.7046, test_accuracy: 0.8512\n",
      "Epoch 11, train_loss: 0.6739, train_accuracy: 0.9355, test_loss: 0.7031, test_accuracy: 0.8552\n",
      "Epoch 12, train_loss: 0.5568, train_accuracy: 0.9249, test_loss: 0.5901, test_accuracy: 0.8532\n",
      "Epoch 13, train_loss: 0.5542, train_accuracy: 0.9279, test_loss: 0.5843, test_accuracy: 0.8700\n",
      "Epoch 14, train_loss: 0.5447, train_accuracy: 0.9405, test_loss: 0.5976, test_accuracy: 0.8492\n",
      "Epoch 15, train_loss: 0.5357, train_accuracy: 0.9518, test_loss: 0.5741, test_accuracy: 0.8869\n",
      "Epoch 16, train_loss: 0.5344, train_accuracy: 0.9515, test_loss: 0.5897, test_accuracy: 0.8571\n",
      "Epoch 17, train_loss: 0.5322, train_accuracy: 0.9551, test_loss: 0.5932, test_accuracy: 0.8522\n",
      "Epoch 18, train_loss: 0.5306, train_accuracy: 0.9584, test_loss: 0.5771, test_accuracy: 0.8810\n",
      "Epoch 19, train_loss: 0.5297, train_accuracy: 0.9588, test_loss: 0.5908, test_accuracy: 0.8581\n"
     ]
    }
   ],
   "source": [
    "commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tf2",
   "language": "python",
   "name": "env-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
